{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面验证 transpose 和 permute 的用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3279, -1.0326],\n",
       "         [ 1.2334, -1.0557]],\n",
       "\n",
       "        [[ 0.3534, -0.5765],\n",
       "         [ 0.0330,  0.3341]],\n",
       "\n",
       "        [[-1.3845,  0.4735],\n",
       "         [ 0.6970,  0.5615]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.randn(12).reshape(3,2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3279,  1.2334],\n",
       "         [-1.0326, -1.0557]],\n",
       "\n",
       "        [[ 0.3534,  0.0330],\n",
       "         [-0.5765,  0.3341]],\n",
       "\n",
       "        [[-1.3845,  0.6970],\n",
       "         [ 0.4735,  0.5615]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = x.transpose(2,1)\n",
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3279,  1.2334],\n",
       "         [-1.0326, -1.0557]],\n",
       "\n",
       "        [[ 0.3534,  0.0330],\n",
       "         [-0.5765,  0.3341]],\n",
       "\n",
       "        [[-1.3845,  0.6970],\n",
       "         [ 0.4735,  0.5615]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = x.permute(0,2,1)\n",
    "x_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多头注意力的实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "dim_embedding = 16\n",
    "num_heads = 8\n",
    "dim_qk = 16\n",
    "dim_v =16\n",
    "sequence_length = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(batch_size,sequence_length,dim_embedding)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_q = nn.Linear(dim_embedding,dim_qk, bias=False)\n",
    "linear_k = nn.Linear(dim_embedding,dim_qk, bias=False)\n",
    "linear_v = nn.Linear(dim_embedding,dim_v, bias = False)\n",
    "\n",
    "normal_factor = ( dim_qk // num_heads) ** -0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_q = dim_qk // num_heads\n",
    "div_v = dim_v // num_heads\n",
    "div_q, div_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q= linear_q(x).view(batch_size,sequence_length,num_heads, div_q).permute(0,2,1,3)\n",
    "\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k= linear_k(x).view(batch_size,sequence_length,num_heads, div_q).permute(0,2,1,3)\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v= linear_v(x).view(batch_size,sequence_length,num_heads,div_v).permute(0,2,1,3)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = torch.matmul(q,k.permute(0,1,3,2)) ** normal_factor\n",
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_socre  = torch.matmul(dist, v) \n",
    "atten_socre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 8, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_socre = atten_socre.permute(0,2,1,3)\n",
    "\n",
    "atten_socre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_socre = atten_socre.contiguous().view(batch_size,sequence_length,dim_v)\n",
    "atten_socre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(2,2)\n",
    "linear2 = nn.Linear(2,4)\n",
    "model =  nn.Sequential(linear,linear2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0530, -0.0046],\n",
      "        [-0.5766, -0.7019]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3891, -0.0369], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4832, -0.2867],\n",
      "        [ 0.5267,  0.6571],\n",
      "        [ 0.3882,  0.5172],\n",
      "        [ 0.1580,  0.4386]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5923,  0.0330,  0.5836,  0.6242], requires_grad=True)\n",
      "0 Linear(in_features=2, out_features=2, bias=True)\n",
      "1 Linear(in_features=2, out_features=4, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)\n",
    "for module in list(model.modules()):\n",
    "    for key,val in module._modules.items():\n",
    "        print(key,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Person():\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "p = Person('John', 36)\n",
    "\n",
    "setattr(p, 'name', 'John')\n",
    "p.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(p, 'sex', 'female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('female', 36, 'John')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sex,p.age,p.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [1, 2, 3], [1, 2, 3]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [[1,2,3]]\n",
    "lst*3\n",
    "## 等价与 [item*3 for item in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (key1,value1),(key2,value2) \u001b[38;5;129;01min\u001b[39;00m [(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m),(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m)]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(key1,value1)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdfsa\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "for (key1,value1),(key2,value2) in [(1,2),(3,4)]:\n",
    "    print(key1,value1)\n",
    "    print(\"dfsa\")\n",
    "    print(key2,value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

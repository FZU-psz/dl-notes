{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面验证 transpose 和 permute 的用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4256, -1.3223],\n",
       "         [ 0.3314, -0.6589]],\n",
       "\n",
       "        [[-0.1577, -0.4315],\n",
       "         [-0.8734, -0.0595]],\n",
       "\n",
       "        [[-1.6218, -0.4744],\n",
       "         [ 0.4396, -0.2176]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.randn(12).reshape(3,2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4256,  0.3314],\n",
       "         [-1.3223, -0.6589]],\n",
       "\n",
       "        [[-0.1577, -0.8734],\n",
       "         [-0.4315, -0.0595]],\n",
       "\n",
       "        [[-1.6218,  0.4396],\n",
       "         [-0.4744, -0.2176]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = x.transpose(2,1)\n",
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4256,  0.3314],\n",
       "         [-1.3223, -0.6589]],\n",
       "\n",
       "        [[-0.1577, -0.8734],\n",
       "         [-0.4315, -0.0595]],\n",
       "\n",
       "        [[-1.6218,  0.4396],\n",
       "         [-0.4744, -0.2176]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = x.permute(0,2,1)\n",
    "x_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多头注意力的实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "dim_embedding = 16\n",
    "num_heads = 8\n",
    "dim_qk = 16\n",
    "dim_v =16\n",
    "sequence_length = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(batch_size,sequence_length,dim_embedding)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_q = nn.Linear(dim_embedding,dim_qk, bias=False)\n",
    "linear_k = nn.Linear(dim_embedding,dim_qk, bias=False)\n",
    "linear_v = nn.Linear(dim_embedding,dim_v, bias = False)\n",
    "\n",
    "normal_factor = ( dim_qk // num_heads) ** -0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_q = dim_qk // num_heads\n",
    "div_v = dim_v // num_heads\n",
    "div_q, div_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q= linear_q(x).view(batch_size,sequence_length,num_heads, div_q).permute(0,2,1,3)\n",
    "\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k= linear_k(x).view(batch_size,sequence_length,num_heads, div_q).permute(0,2,1,3)\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v= linear_v(x).view(batch_size,sequence_length,num_heads,div_v).permute(0,2,1,3)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = torch.matmul(q,k.permute(0,1,3,2)) ** normal_factor\n",
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_socre  = torch.matmul(dist, v) \n",
    "atten_socre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 8, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_socre = atten_socre.permute(0,2,1,3)\n",
    "\n",
    "atten_socre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 16])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_socre = atten_socre.contiguous().view(batch_size,sequence_length,dim_v)\n",
    "atten_socre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
